  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% -*- coding: utf-8; mode: latex -*- %%
  %
%%%%%                       CHAPTER
 %%%
  %

\chapter{Conclusions}
%\addcontentsline{lof}{chapter}{\thechapter\quad Nihil Molestiae}
%\addcontentsline{lot}{chapter}{\thechapter\quad Nihil Molestiae}
\label{ch:magna}

%\begin{quotation}
%  {\small\it Neque porro quisquam est qui dolorem ipsum quia dolor sit amet, consectetur, adipisci velit...}

%{\small\it -- Cerico}
%\end{quotation}

There are a number of paths to continue this work. \\
First, the current pipeline presents some limitations that should be addressed. As previously described, there are complexity limitations associated with abstract features, such as \gls{plp}s and \gls{mfcc}s. By using simpler features, such as Logarithmic Filter Banks (instead of \gls{mfcc}) would increase the ability of the medical professional to understand, and therefore trust, the model's output. In addition, graphical representations of the physical manifestation of each feature can be added to the explanation. The normal values for some features, such as \gls{f0}, depend on meta features (the normal values for \gls{f0} for males is between 105 and 160 Hz, while for females it's 175 to 245 \textit{Hz}). Thus, adding the gender as a feature for the model would provide important information which could help improve the model's performance. \\
Both the classification and explanation pipeline's steps have further aspects to be explored. Namely, the similarity between the average contribution (weight) value of each feature on the explanation model suggested some correlation between features. This hypothesis can be further studied, using a model to evaluate the interactions between features, such as factorization machines. Detecting redundant features could help reduce the model's complexity, thus reducing resource necessity. Also, the results achieved on the semi language-independent experiments showed that there was no performance loss when training a model with two languages. Further analysis on the impact of varying the training percentage of the test language would shed light into the relation between data quantity used to re-train a model and the eventual performance loss. Moreover, this work focuses on explaining the diagnosis of each patient. A study on the global contributions of each feature could clarify the their individual importance to the \gls{pd} classification task. This could be done by using LIME to generate global explanations', or by using models such as \gls{cav}s \cite{TCAV} or \gls{nam}s \cite{NAM}. Finally, both for the classification and explanations' steps, different models can be used to make a comparative analysis. This would allow to both assess the classification ability of multiple models, but also to compare the explanations generated by various models and the trust provided to the medical professionals. \\
The goal of generating explanations is to provide the medical professionals with a tool that can shed light into the \textit{black-box} classification models. Thus, these models should be tested in real-world scenarios, to rate their adequacy to perform this task. During the real-world evaluation, a comparative analysis could be conducted between explainability models, in order to assess which ones provide more trust to the end users for the product (the medical professionals). This can be done by generating explanations for the same user using different explainability models and assessing the degree of confidence of the medical professional in each one of them. This evaluation could also lead to the conclusion that a combination of both methods provides more information, which would provide a higher level of trust by the medical professional on the classification models. Feature types (such as audio ou images) should also be compared, as to understand which are more adequate to be used by medical professionals. For example, the explanations generated by the model developed during this work could be compared with ones produced by the work described on section 3.3, in which LIME was used to explain \gls{pd} diagnostic with SPECT DaTSCAN images of the brain. 
  %
 %%%
%%%%%                           THE END
  %
  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "tese"
%%% End: 
