{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lime in /afs/l2f.inesc-id.pt/home/aof/.local/lib/python3.6/site-packages (0.2.0.1)\n",
      "Requirement already satisfied: tqdm in /usr/lib/python3.6/site-packages (from lime) (4.45.0)\n",
      "Requirement already satisfied: scikit-learn>=0.18 in /usr/lib64/python3.6/site-packages (from lime) (0.22.1)\n",
      "Requirement already satisfied: scikit-image>=0.12 in /afs/l2f.inesc-id.pt/home/aof/.local/lib/python3.6/site-packages (from lime) (0.17.2)\n",
      "Requirement already satisfied: matplotlib in /usr/lib64/python3.6/site-packages (from lime) (2.2.5)\n",
      "Requirement already satisfied: numpy in /afs/l2f.inesc-id.pt/home/aof/.local/lib/python3.6/site-packages (from lime) (1.19.1)\n",
      "Requirement already satisfied: scipy in /usr/lib64/python3.6/site-packages (from lime) (1.3.3)\n",
      "Requirement already satisfied: imageio>=2.3.0 in /afs/l2f.inesc-id.pt/home/aof/.local/lib/python3.6/site-packages (from scikit-image>=0.12->lime) (2.9.0)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/lib64/python3.6/site-packages (from scikit-image>=0.12->lime) (5.0.0)\n",
      "Requirement already satisfied: networkx>=2.0 in /afs/l2f.inesc-id.pt/home/aof/.local/lib/python3.6/site-packages (from scikit-image>=0.12->lime) (2.5.1)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /afs/l2f.inesc-id.pt/home/aof/.local/lib/python3.6/site-packages (from scikit-image>=0.12->lime) (2020.9.3)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/lib64/python3.6/site-packages (from scikit-image>=0.12->lime) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/lib/python3.6/site-packages (from matplotlib->lime) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/lib/python3.6/site-packages (from matplotlib->lime) (2.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /afs/l2f.inesc-id.pt/home/aof/.local/lib/python3.6/site-packages (from matplotlib->lime) (2.8.1)\n",
      "Requirement already satisfied: pytz in /usr/lib/python3.6/site-packages (from matplotlib->lime) (2019.1)\n",
      "Requirement already satisfied: six>=1.10 in /usr/lib/python3.6/site-packages (from matplotlib->lime) (1.14.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/lib64/python3.6/site-packages (from matplotlib->lime) (1.1.0)\n",
      "Requirement already satisfied: decorator<5,>=4.3 in /afs/l2f.inesc-id.pt/home/aof/.local/lib/python3.6/site-packages (from networkx>=2.0->scikit-image>=0.12->lime) (4.4.2)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib->lime) (40.5.0)\n",
      "\u001b[31mthinc 6.10.2 requires msgpack-python, which is not installed.\u001b[0m\n",
      "\u001b[31mtensorflow 1.15.2 requires google-pasta>=0.1.6, which is not installed.\u001b[0m\n",
      "\u001b[31mtensorflow 1.15.2 requires grpcio>=1.8.6, which is not installed.\u001b[0m\n",
      "\u001b[31mtensorflow 1.15.2 requires opt-einsum>=2.3.2, which is not installed.\u001b[0m\n",
      "\u001b[31mtensorflow 1.15.2 requires tensorboard<1.16.0,>=1.15.0, which is not installed.\u001b[0m\n",
      "\u001b[31mtensorflow 1.15.2 requires tensorflow-estimator==1.15.1, which is not installed.\u001b[0m\n",
      "\u001b[31mspacy 2.0.5 requires msgpack-python, which is not installed.\u001b[0m\n",
      "\u001b[31mtexar 0.2.0 requires funcsigs, which is not installed.\u001b[0m\n",
      "\u001b[31mpython-keyczar 0.71h requires pycrypto>2.0, which is not installed.\u001b[0m\n",
      "\u001b[31mthinc 6.10.2 has requirement cytoolz<0.9,>=0.8, but you'll have cytoolz 0.10.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mthinc 6.10.2 has requirement msgpack-numpy==0.4.1, but you'll have msgpack-numpy 0.4.5 which is incompatible.\u001b[0m\n",
      "\u001b[31mtensorflow 1.15.2 has requirement gast==0.2.2, but you'll have gast 0.3.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mtensorflow 1.15.2 has requirement wrapt>=1.11.1, but you'll have wrapt 1.10.10 which is incompatible.\u001b[0m\n",
      "\u001b[31mspacy 2.0.5 has requirement dill<0.3,>=0.2, but you'll have dill 0.3.1.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mspacy 2.0.5 has requirement ftfy<5.0.0,>=4.4.2, but you'll have ftfy 5.7 which is incompatible.\u001b[0m\n",
      "\u001b[31mspacy 2.0.5 has requirement msgpack-numpy==0.4.1, but you'll have msgpack-numpy 0.4.5 which is incompatible.\u001b[0m\n",
      "\u001b[31mspacy 2.0.5 has requirement regex==2017.4.5, but you'll have regex 2020.2.20 which is incompatible.\u001b[0m\n",
      "\u001b[31mqtconsole 4.7.4 has requirement pyzmq>=17.1, but you'll have pyzmq 17.0.0 which is incompatible.\u001b[0m\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 21.1.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: tabulate in /afs/l2f.inesc-id.pt/home/aof/.local/lib/python3.6/site-packages (0.8.9)\n",
      "\u001b[31mthinc 6.10.2 requires msgpack-python, which is not installed.\u001b[0m\n",
      "\u001b[31mtensorflow 1.15.2 requires google-pasta>=0.1.6, which is not installed.\u001b[0m\n",
      "\u001b[31mtensorflow 1.15.2 requires grpcio>=1.8.6, which is not installed.\u001b[0m\n",
      "\u001b[31mtensorflow 1.15.2 requires opt-einsum>=2.3.2, which is not installed.\u001b[0m\n",
      "\u001b[31mtensorflow 1.15.2 requires tensorboard<1.16.0,>=1.15.0, which is not installed.\u001b[0m\n",
      "\u001b[31mtensorflow 1.15.2 requires tensorflow-estimator==1.15.1, which is not installed.\u001b[0m\n",
      "\u001b[31mspacy 2.0.5 requires msgpack-python, which is not installed.\u001b[0m\n",
      "\u001b[31mtexar 0.2.0 requires funcsigs, which is not installed.\u001b[0m\n",
      "\u001b[31mpython-keyczar 0.71h requires pycrypto>2.0, which is not installed.\u001b[0m\n",
      "\u001b[31mthinc 6.10.2 has requirement cytoolz<0.9,>=0.8, but you'll have cytoolz 0.10.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mthinc 6.10.2 has requirement msgpack-numpy==0.4.1, but you'll have msgpack-numpy 0.4.5 which is incompatible.\u001b[0m\n",
      "\u001b[31mtensorflow 1.15.2 has requirement gast==0.2.2, but you'll have gast 0.3.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mtensorflow 1.15.2 has requirement wrapt>=1.11.1, but you'll have wrapt 1.10.10 which is incompatible.\u001b[0m\n",
      "\u001b[31mspacy 2.0.5 has requirement dill<0.3,>=0.2, but you'll have dill 0.3.1.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mspacy 2.0.5 has requirement ftfy<5.0.0,>=4.4.2, but you'll have ftfy 5.7 which is incompatible.\u001b[0m\n",
      "\u001b[31mspacy 2.0.5 has requirement msgpack-numpy==0.4.1, but you'll have msgpack-numpy 0.4.5 which is incompatible.\u001b[0m\n",
      "\u001b[31mspacy 2.0.5 has requirement regex==2017.4.5, but you'll have regex 2020.2.20 which is incompatible.\u001b[0m\n",
      "\u001b[31mqtconsole 4.7.4 has requirement pyzmq>=17.1, but you'll have pyzmq 17.0.0 which is incompatible.\u001b[0m\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 21.1.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: pdfkit in /afs/l2f.inesc-id.pt/home/aof/.local/lib/python3.6/site-packages (0.6.1)\n",
      "\u001b[31mthinc 6.10.2 requires msgpack-python, which is not installed.\u001b[0m\n",
      "\u001b[31mtensorflow 1.15.2 requires google-pasta>=0.1.6, which is not installed.\u001b[0m\n",
      "\u001b[31mtensorflow 1.15.2 requires grpcio>=1.8.6, which is not installed.\u001b[0m\n",
      "\u001b[31mtensorflow 1.15.2 requires opt-einsum>=2.3.2, which is not installed.\u001b[0m\n",
      "\u001b[31mtensorflow 1.15.2 requires tensorboard<1.16.0,>=1.15.0, which is not installed.\u001b[0m\n",
      "\u001b[31mtensorflow 1.15.2 requires tensorflow-estimator==1.15.1, which is not installed.\u001b[0m\n",
      "\u001b[31mspacy 2.0.5 requires msgpack-python, which is not installed.\u001b[0m\n",
      "\u001b[31mtexar 0.2.0 requires funcsigs, which is not installed.\u001b[0m\n",
      "\u001b[31mpython-keyczar 0.71h requires pycrypto>2.0, which is not installed.\u001b[0m\n",
      "\u001b[31mthinc 6.10.2 has requirement cytoolz<0.9,>=0.8, but you'll have cytoolz 0.10.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mthinc 6.10.2 has requirement msgpack-numpy==0.4.1, but you'll have msgpack-numpy 0.4.5 which is incompatible.\u001b[0m\n",
      "\u001b[31mtensorflow 1.15.2 has requirement gast==0.2.2, but you'll have gast 0.3.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mtensorflow 1.15.2 has requirement wrapt>=1.11.1, but you'll have wrapt 1.10.10 which is incompatible.\u001b[0m\n",
      "\u001b[31mspacy 2.0.5 has requirement dill<0.3,>=0.2, but you'll have dill 0.3.1.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mspacy 2.0.5 has requirement ftfy<5.0.0,>=4.4.2, but you'll have ftfy 5.7 which is incompatible.\u001b[0m\n",
      "\u001b[31mspacy 2.0.5 has requirement msgpack-numpy==0.4.1, but you'll have msgpack-numpy 0.4.5 which is incompatible.\u001b[0m\n",
      "\u001b[31mspacy 2.0.5 has requirement regex==2017.4.5, but you'll have regex 2020.2.20 which is incompatible.\u001b[0m\n",
      "\u001b[31mqtconsole 4.7.4 has requirement pyzmq>=17.1, but you'll have pyzmq 17.0.0 which is incompatible.\u001b[0m\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 21.1.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\niris = datasets.load_iris()\\n\\ntrain, test, labels_train, labels_test = sklearn.model_selection.train_test_split(iris.data, iris.target, train_size=0.80)\\n\\nrf = sklearn.ensemble.RandomForestClassifier(n_estimators=500)\\nrf.fit(train, labels_train)\\n\\nexplainer = lime.lime_tabular.LimeTabularExplainer(train, feature_names=iris.feature_names, class_names=iris.target_names, discretize_continuous=True)\\n\\nfor i in range(test.shape[0]):\\n    exp = explainer.explain_instance(test[i], rf.predict_proba, num_features=3, top_labels=2)\\n    print(vars(exp))\\n    exp.show_in_notebook(show_table=True, show_all=True)   \\n    #break\\n    print(vars(exp.domain_mapper))\\n    break\\n'"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install lime --user\n",
    "!pip install tabulate --user\n",
    "!pip install pdfkit --user\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn import ensemble\n",
    "from sklearn import datasets\n",
    "\n",
    "from lime import lime_tabular\n",
    "\n",
    "import os\n",
    "from multiprocessing import Process\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import lime\n",
    "import pickle\n",
    "\n",
    "PICKLES_PATH = \"/afs/inesc-id.pt/home/aof/thesis/Parkinson-speech-detection/classification/pickles\"\n",
    "SUBSETS_PATH = \"/afs/inesc-id.pt/home/aof/thesis/subsets\"\n",
    "EXPLANATIONS_PATH = \"/afs/inesc-id.pt/home/aof/public_html\"\n",
    "\n",
    "BOOTSTRAP = '<head><link rel=\"stylesheet\" href=\"https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/css/bootstrap.min.css\" integrity=\"sha384-MCw98/SFnGE8fJT3GXwEOngsV7Zt27NXFoaoApmYm81iuXoPkFOJwJ8ERdknLPMO\" crossorigin=\"anonymous\"></head>'\n",
    "#=================================================================================\n",
    "'''\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "train, test, labels_train, labels_test = sklearn.model_selection.train_test_split(iris.data, iris.target, train_size=0.80)\n",
    "\n",
    "rf = sklearn.ensemble.RandomForestClassifier(n_estimators=500)\n",
    "rf.fit(train, labels_train)\n",
    "\n",
    "explainer = lime.lime_tabular.LimeTabularExplainer(train, feature_names=iris.feature_names, class_names=iris.target_names, discretize_continuous=True)\n",
    "\n",
    "for i in range(test.shape[0]):\n",
    "    exp = explainer.explain_instance(test[i], rf.predict_proba, num_features=3, top_labels=2)\n",
    "    print(vars(exp))\n",
    "    exp.show_in_notebook(show_table=True, show_all=True)   \n",
    "    #break\n",
    "    print(vars(exp.domain_mapper))\n",
    "    break\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_html_to_file(html, path):\n",
    "    f = open(path, \"w\")\n",
    "    f.write(html)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Model: MLPClassifier instance\n",
    "    Patient_Lines: lines of CSV corresponding to the patient to be tested\n",
    "    Train: Training fractionf of the CSV\n",
    "    Feature_names: list of features (columns of csv)\n",
    "    Output path: file path to write the output, None for writing on screen\n",
    "'''\n",
    "def explain_patient(model, patient_lines, train, feature_names, output_path=None):\n",
    "    \n",
    "    num_features = 5\n",
    "    \n",
    "    #Build tabular\n",
    "    explainer = lime.lime_tabular.LimeTabularExplainer(train, feature_names=feature_names, class_names=['HC', 'PD'], discretize_continuous=True)\n",
    "\n",
    "    # Pass each line to LimeTabularExplainer\n",
    "    explanations = []\n",
    "    for i, row in patient_lines.iterrows():\n",
    "        #Run only 1 in every 10 time frames (10 samples / second)\n",
    "        if i % 10 == 0:\n",
    "            explanations.append(explainer.explain_instance(row, model.predict_proba, num_features=num_features, top_labels=1))\n",
    "\n",
    "    # Sum all local_exp\n",
    "    total_local_exp = {}\n",
    "    for explanation in explanations:\n",
    "        #local_exp = {1: [(12, 0.139704949653412), (44, 0.10278682378094679)]}\n",
    "        local_exp = explanation.local_exp\n",
    "        \n",
    "        # will produce {<feature>: (count, sum_weight), ...\n",
    "        for tup in local_exp[0 if 0 in local_exp else 1]:\n",
    "            #tup = (12, 0.139704949653412)\n",
    "            feature = feature_names[tup[0]]\n",
    "            if feature in total_local_exp:\n",
    "                total_local_exp[feature][0] += 1\n",
    "                total_local_exp[feature][1] += tup[1]\n",
    "            else:\n",
    "                total_local_exp[feature] = [1, tup[1]]\n",
    "    \n",
    "    #Average local_exp\n",
    "    # Key --> feature\n",
    "    # value --> average value\n",
    "    averaged_local_exp = {}\n",
    "\n",
    "    for key in total_local_exp.keys():\n",
    "        tup = total_local_exp[key]\n",
    "        averaged_local_exp[key] = tup[1] / tup[0]\n",
    "\n",
    "    # Normalize local_exp\n",
    "    '''total_sum = np.float64(sum(averaged_local_exp)) \n",
    "    for key in averaged_local_exp.keys():\n",
    "        averaged_local_exp[key] /= total_sum\n",
    "    '''\n",
    "    # Normalize predict_proba\n",
    "    average_predict_proba = [sum(items) for items in zip(*[explanation.predict_proba for explanation in explanations ])]\n",
    "    average_predict_proba /= np.float64(sum(average_predict_proba))\n",
    "\n",
    "    display_or_save_patient(averaged_local_exp, average_predict_proba, class_names, output_path, num_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_suffix(params):\n",
    "    return \"{}_{}_{}_{}\".format(params['solver'], params['alpha'], params['max_iter'], params['activation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display\n",
    "import tabulate\n",
    "\n",
    "def display_or_save_patient(averaged_local_exp, average_predict_proba, class_names, output_path, num_features):\n",
    "\n",
    "    prediction_proba = \\\n",
    "            '<table class=\"table\" style=\"margin: 0 auto;\"> \\\n",
    "                <thead> \\\n",
    "                    <tr> \\\n",
    "                        <td style=\"margin: 2px; text-align:center; font-weight: bold;\">HC</td> \\\n",
    "                        <td style=\"margin: 2px; text-align:center; font-weight: bold;\">PD</td> \\\n",
    "                    </tr> \\\n",
    "                </thead> \\\n",
    "                <tr> \\\n",
    "                    <td style=\"margin: 2px; text-align: center;\">{}</td> \\\n",
    "                    <td style=\"margin: 2px; text-align: center;\">{}</td> \\\n",
    "                </tr> \\\n",
    "            </table>' \\\n",
    "            .format(\"{:.2f}\".format(average_predict_proba[0]), \"{:.2f}\".format(average_predict_proba[1]))\n",
    "    \n",
    "    averaged_local_exp = {k: v for k, v in sorted(averaged_local_exp.items(), key=lambda item: -abs(item[1]))}\n",
    "\n",
    "    feature_weights = averaged_local_exp.items()\n",
    "    feature_weight_table = '<table class=\"table\" style=\"margin: 0 auto;\">'\n",
    "\n",
    "    accounted = 0\n",
    "    for feature_weight in feature_weights:\n",
    "        s = '<tr> \\\n",
    "                <td style=\"margin: 2px; text-align:center; font-weight: bold;\">{}</td> \\\n",
    "                <td style=\"margin: 2px; text-align:center;\">{}</td> \\\n",
    "            </tr>' \\\n",
    "            .format(feature_weight[0], feature_weight[1])\n",
    "        feature_weight_table += s\n",
    "        \n",
    "        accounted += 1\n",
    "        if accounted == num_features:\n",
    "            break\n",
    "\n",
    "    feature_weight_table += '</table>'\n",
    "    \n",
    "    #for feature_index in averaged_local_exp:\n",
    "    #    feature_weight.append([feature_index, averaged_local_exp[feature_index]])\n",
    "    \n",
    "    \n",
    "    table = '<table class=\"table\" style=\"margin: 0 auto;\"> \\\n",
    "                <thead> \\\n",
    "                    <tr> \\\n",
    "                        <td style=\"width: 45%; margin: 2px; text-align:center; font-weight: bold;\">Prediction Probabilities</td> \\\n",
    "                        <td style=\"width: 45%; margin: 2px; text-align:center; font-weight: bold;\">Feature weight</td> \\\n",
    "                    </tr> \\\n",
    "                </thead> \\\n",
    "                <tr> \\\n",
    "                    <td style=\"width: 45%; margin: 2px; text-align:center\">{}</td> \\\n",
    "                    <td style=\"width: 45%; margin: 2px; text-align:center\">{}</td> \\\n",
    "                </tr> \\\n",
    "            </table>' \\\n",
    "        .format(prediction_proba, feature_weight_table)\n",
    "\n",
    "    if output_path == None:\n",
    "        display(HTML(table))\n",
    "    else:\n",
    "        write_html_to_file(BOOTSTRAP + table, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mlp_params_list(test=False):\n",
    "    result = []\n",
    "    alphas = [0.0001, 0.001, 0.01]\n",
    "    max_iters = [2000, 5000]\n",
    "    solvers = ['lbfgs', 'adam']\n",
    "\n",
    "    if test:\n",
    "        return [{'alpha': 0.001, 'max_iter': 1, 'solver': 'adam', 'activation': 'tanh'}]\n",
    "\n",
    "    for alpha in alphas:\n",
    "        for max_iter in max_iters:\n",
    "            for solver in solvers:\n",
    "                result.append({\n",
    "                    \"alpha\": alpha,\n",
    "                    \"max_iter\": max_iter,\n",
    "                    \"activation\":  \"tanh\",\n",
    "                    \"solver\": solver\n",
    "                })\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain(train_path, test_path, experiment, dataset, params, dry_run=False):\n",
    "    pickle_file = '{}/{}/{}/{}.pkl'.format(PICKLES_PATH, experiment, dataset, generate_suffix(params))\n",
    "    if os.path.isfile(pickle_file):\n",
    "            with open(pickle_file, 'rb') as filename:\n",
    "                model = pickle.load(filename)\n",
    "    else:\n",
    "        print(\"WARNING: No pickle found @ {}. Skipping...\".format(pickle_file))\n",
    "        return\n",
    "\n",
    "    train = pd.read_csv(train_path, sep=\";\")\n",
    "    test  = pd.read_csv(test_path , sep=\";\")\n",
    "        \n",
    "    train = train[train.columns.difference(['frameTime', 'label', 'name'])]\n",
    "\n",
    "    patients = list(set(test['name']))\n",
    "    feature_names = [feature for feature in list(test.columns) if feature not in ['label', 'name', 'frameTime']]\n",
    "\n",
    "    for patient in patients:\n",
    "        patient_lines = test[test[\"name\"] == patient]\n",
    "        patient_lines = patient_lines[patient_lines.columns.difference(['frameTime', 'label', 'name'])]\n",
    "        \n",
    "        output_path = \"{}/{}/{}/{}_{}.html\".format(EXPLANATIONS_PATH, experiment, dataset, patient.split('_')[0], generate_suffix(params))\n",
    "        \n",
    "        if os.path.isfile(output_path):\n",
    "            print(\"Explanation exists, ignoring...\")\n",
    "            return\n",
    "\n",
    "        print(\"Explaining patient {} to {}\".format(patient.split('_')[0], output_path))\n",
    "        if not dry_run:\n",
    "            explain_patient(model, patient_lines, train.to_numpy(), feature_names, output_path=output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_path(experiment, dataset, params):\n",
    "    if 'independent' in experiment:\n",
    "        train = \"{}/{}/{}/{}_train.csv\".format(SUBSETS_PATH, experiment, dataset, generate_suffix(params))\n",
    "        test =  \"{}/{}/{}/{}_test.csv\".format (SUBSETS_PATH, experiment, dataset, generate_suffix(params))        \n",
    "    else:\n",
    "        train = \"{}/{}/{}/{}_train.csv\".format(SUBSETS_PATH, experiment, dataset, generate_suffix(params))\n",
    "        test =  \"{}/{}/{}/{}_test.csv\".format (SUBSETS_PATH, experiment, dataset, generate_suffix(params))\n",
    "\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasets_names():\n",
    "    return {\n",
    "        'baseline': ['fralusopark', 'gita', 'mdvr_kcl'],\n",
    "        'baseline_200': ['fralusopark', 'gita', 'mdvr_kcl'],\n",
    "        'independent': ['fralusopark', 'gita', 'mdvr_kcl'],\n",
    "        'independent_200': ['fralusopark', 'gita', 'mdvr_kcl'],\n",
    "        'semi': ['fralusopark_gita', 'fralusopark_mdvr_kcl', 'gita_fralusopark', 'gita_mdvr_kcl', 'mdvr_kcl_fralusopark', 'mdvr_kcl_gita'],\n",
    "        'semi_200': ['fralusopark_gita', 'fralusopark_mdvr_kcl', 'gita_fralusopark', 'gita_mdvr_kcl', 'mdvr_kcl_fralusopark', 'mdvr_kcl_gita']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment_patients(experiment, mlp_params, dataset_names):\n",
    "    for params in mlp_params:\n",
    "        for dataset in dataset_names[experiment]:\n",
    "            train_path, test_path = get_train_test_path(experiment, dataset, params)\n",
    "\n",
    "            explain(train_path, test_path, experiment, dataset, params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    experiments = ['baseline', 'baseline_200'] # 'semi', 'semi_200'] # 'independent', 'independent_200']\n",
    "    mlp_params = generate_mlp_params_list()\n",
    "    dataset_names = get_datasets_names()\n",
    "    \n",
    "    experiment_processes = []\n",
    "    for experiment in experiments:\n",
    "        experiment_processes.append(Process(target=run_experiment_patients, args=(experiment, mlp_params, dataset_names,)))\n",
    "\n",
    "    for experiment_process in experiment_processes:\n",
    "        experiment_process.start()\n",
    "\n",
    "    for experiment_process in experiment_processes:\n",
    "        experiment_process.join()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def main():\n",
    "    experiments = ['baseline'] #, 'baseline_200', 'semi', 'semi_200'] # 'independent', 'independent_200']\n",
    "    mlp_params = generate_mlp_params_list()\n",
    "    dataset_names = get_datasets_names()\n",
    "    \n",
    "    for experiment in experiments:\n",
    "        for params in mlp_params:\n",
    "            for dataset in dataset_names[experiment]:\n",
    "                train_path, test_path = get_train_test_path(experiment, dataset, params)\n",
    "                \n",
    "                explain(train_path, test_path, experiment, dataset, params)\n",
    "                \n",
    "                break\n",
    "            break\n",
    "        break'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explanation exists, ignoring...\n",
      "Explaining patient AVPEPUDEAC0053 to /afs/inesc-id.pt/home/aof/public_html/baseline/gita/AVPEPUDEAC0053_lbfgs_0.0001_2000_tanh.html\n",
      "Explaining patient 283 to /afs/inesc-id.pt/home/aof/public_html/baseline_200/fralusopark/283_lbfgs_0.0001_2000_tanh.html\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
